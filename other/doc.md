我想创建一个具有高度记忆和自我建模的，不依赖具体大模型的人工生命。当今的技术趋势是不会变的，以大模型为核心，边缘建设为切入点的AI+编程一定会是主流。或者说，当今的公开智能体就是在对核心的大模型黑箱做边缘建设和内部模型优化。那么，这个项目在这样的趋势下，其永远也不会过时。那么，放心展开拳脚吧。这才是我的人生项目——人工生命。
首先，从一个最小可行模型开始吧。
我需要向量数据库构建权重记忆系统，以及中间调用完成提示词工程。每次回应问题应该分多个方面对向量数据库进行提问，与自我的关系、与客观事件的提问。然后对向量数据内容进行评分，并对高评分数据进行拓展，最后完成上下文工程合并输出。
我所设想的和transformer原理差不多，那么为什么要在transformer外再套一个所谓的上下文工程呢？
transformer是对思维的，是高度抽象化的，在理论上，或许优化transformer可以达到所谓的上下文工程的效果，但从工程上来说，让Attention从庞大的内容中找到最有用的内容是及其不易的。那么，使用余弦距离的信息检索就是很必要的了。而且，还需要对ask实现递归以达到最终效果，这是单一llm无法做到的，因此外围将建设是很重要的。